---
title: "SELECT, FROM & WHERE"
format:
  html:
    code-fold: false
    code-tools: true
jupyter: python3
---


# The First Tools

SQL is a broad language with commands for [Introduce about DDL, DQL, DML, DCL and TCL]

![Subset of commands on SQL](images/subset_sql.png){width=85% fig-align="center" fig-cap="Subset of SQL languages"}

In SQL, DQL (Data-Query Language) is a subset of commands that is focused on retrieving data from tables. The knowledge on this specific subset of SQL commands are important so the actor can retrieve the data in a way it will help us answer questions with an analytical approach. 

Bigquery is a very DQL-centric database, by this way our queries are optimized to **SELECT** information (columns) from tables and manipulate them accordingly.

To retrieve information from a table, we need to inform for the query engine which table we want to retrieve information **FROM**

This leads us for the most basic command to fetch information from any SQL based databases:

```{python}
#| echo: False

from utils import custom_display_sql

query = """
SELECT * FROM `bigquery-public-data.openaq.global_air_quality`
"""

custom_display_sql(query)
```

SELECT * is known as "SELECT star" and is a way to fetch all the columns from the table. This technique looks easy and efortless, however it's not optimal to run this to retrieve information from table that are too big since it may increase the cloud cost significantly due to the usage of computational resources.


Another important command to learn is the filtering functionality "WHERE". With this command we may filter out results for the author's analysis. For example, if we are analyzing air quality, we may want to analyze the data from a specific country, for example, Brazil. This can be done with the following query:

```{python}
#| echo: False

from utils import custom_display_sql

query = """
SELECT * FROM `bigquery-public-data.openaq.global_air_quality`
WHERE country = "BR"
"""
custom_display_sql(query)
```

To reduce the usage of computational resources (costs), one way is to filter the number of columns you are currently retrieving. Another way is to 
-- Sometimes you are going to be dealing with huge number of data, this is why it's important to filter, or to limit the data.

```{python}
#| echo: False

# with this I can hide the code that is used
import pandas as pd
from utils import custom_display_sql, custom_display_df

query = """
SELECT 
    user_id
    , COUNT(*) as total
FROM 
    `project.dataset.table`
WHERE 
    event_date >= '2024-01-01'
GROUP BY user_id
ORDER BY total DESC
LIMIT 10;
"""

# Wrap it in code block markdown with SQL
custom_display_sql(query)

data = pd.DataFrame(
    [
        [1,2,1],
        [2,3,4],
        [3,4,9]
    ],
    columns = ['numbers', 'plus_one', 'square']
)

custom_display_df(data)
```
